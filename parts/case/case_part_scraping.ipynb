{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import reshape\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read saved csv file as dataframe\n",
    "df = pd.read_csv('case_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/andrewcaffey/Documents/Projects/Data/PCPP/Part_Scraping/case/parts/\")\n",
    "part_list = []\n",
    "comments = []\n",
    "for i in os.listdir(os.getcwd()):\n",
    "    a = open(i, 'r')\n",
    "    #print a.read()\n",
    "    b = BeautifulSoup(a)\n",
    "\n",
    "    #basic info\n",
    "    if b.find('h4', attrs={'class':'kind'}) != None:\n",
    "        kind = b.find('h4', attrs={'class':'kind'}).text\n",
    "        part_name = b.find('h1', attrs={'class':'name'}).text\n",
    "        link = b.find('input', attrs={'name':'url'})['value']\n",
    "        info_dict = {'Kind':kind, 'Name':part_name, 'Link': link}\n",
    "\n",
    "        #prices\n",
    "        if b.find_all('td', attrs={'class':'base'}) != None:\n",
    "            price_list = b.find_all('td', attrs={'class':'base'})\n",
    "            price_list = [float(x.text.strip('$')) for x in price_list]\n",
    "            #average_price = sum(price_list)/len(price_list)\n",
    "            price_dict = {'Prices':price_list,}\n",
    "\n",
    "        #specs\n",
    "        spec_labels = b.find('div', attrs={'class':'specs block'}).find_all('h4')\n",
    "        spec_labels = [x.contents[0] for x in spec_labels]\n",
    "        spec_values = str(b.find('div', attrs={'class':'specs block'}))\n",
    "\n",
    "        vals = [x.strip().split('</h4>')[1].strip('\\n').strip() for x in spec_values.split(\"<h4>\")[1:]]\n",
    "        vals[-1] = vals[-1].split('\\n')[0]\n",
    "        spec_values = vals\n",
    "\n",
    "        spec_values = spec_values[0:len(spec_labels)+1]\n",
    "        spec_dict = {spec_label:spec_value for spec_label, spec_value in zip(spec_labels,spec_values)}\n",
    "\n",
    "        part_dict = dict(spec_dict.items() + info_dict.items() + price_dict.items())\n",
    "        part_list.append(part_dict)\n",
    "\n",
    "        #reviews\n",
    "    reviews = b.find('div', attrs={'class':'part-reviews'})\n",
    "    if reviews != None:\n",
    "        reviews = reviews.find_all('div',attrs={'class':'part-review-block'})\n",
    "        star_list = [len(reviews[x].find('ul',attrs={'class':'stars'}).find_all('li',attrs={'class':'full-star'})) for x in range(len(reviews))]\n",
    "\n",
    "        comment_text_list = b.find_all('div', attrs={'class':'comment-message markdown'})\n",
    "        comment_text_list = [comment_text_list[x].find_all('p') for x in range(len(comment_text_list))]\n",
    "\n",
    "        comment_text_list_clean = []\n",
    "        for i, x in enumerate(comment_text_list):\n",
    "            comment = \"\"\n",
    "            for y in x:\n",
    "                try:\n",
    "                    comment += y.contents[0] + \" \"\n",
    "                except:\n",
    "                    pass\n",
    "            comment_text_list_clean.append(comment)\n",
    "\n",
    "        \n",
    "\n",
    "        review = zip(star_list, comment_text_list_clean)\n",
    "        \n",
    "        comments.append(review)\n",
    "\n",
    "    a.close()\n",
    "    b.decompose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(part_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cleaning\n",
    "\n",
    "\n",
    "#plot volume against price\n",
    "df['dim'] = [re.sub(r'\"', '', x) if type(x)==str else None for x in df.Dimensions]\n",
    "df['dim'] = [re.sub(r' ', '', x) if type(x)==str else None for x in df.dim]\n",
    "df['dim'] = [x.split('x') if type(x)==str else None for x in df.dim]\n",
    "df['vol'] = [float(x[0])*float(x[1])*float(x[2]) if type(x)==list else None for x in df.dim]\n",
    "df.vol = [x if x != np.nan else 0 for x in df.vol]\n",
    "df.vol = df.vol.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "#average price\n",
    "df['avg'] = [sum(x)/len(x) if len(x)>0 else 0 for x in df.Prices]\n",
    "\n",
    "\n",
    "\n",
    "#short_link\n",
    "df['short_link'] = [x.split('/')[-1] for x in df.Link]\n",
    "\n",
    "stars = [x[0][0] for x in comments[:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save df to local csv file\n",
    "df.to_csv('case_csv.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read saved csv file as dataframe\n",
    "df = pd.read_csv('case_csv.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
